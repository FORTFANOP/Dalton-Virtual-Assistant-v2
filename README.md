# Dalton-Virtual-Assistant-v2
A version 2 of the initial Virtual Assistant I had created last year. This version includes improved speech recognition, multiple new functionalities, along with an AI neural network which runs through the user input and gets back with the most relevant result. (Not very advanced, future plans include integrating this into GPT architecture (someone pls help))

## Usage
By default, when executed, Dalton is in sleep mode. In order to wake Dalton up, speak out the hot word `activate`.  
Once it is activated, `Listening...` is printed out and only then, you should speak(otherwise your message can get cut).  
After the message is spoken, Dalton recognizes the text (`Recognizing...`) via Google's speech recognition API, and a relevant response is generated by the neural network model.
This reply is then spoken out using `pyttsx3` module (couldn't find any other offline module) which converts the text into speech.  
Something to keep in mind is that `pyttsx3` sounds robotic, which in this case, is what I want, so be mindful of that while working with the module.

## Functionalities
As of this version, the following are the funcionalities of Dalton:  
